{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_train_n_evaluation_w_builtin_methods.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PoCow1m6gaF_",
        "KUZlHV_jgkZR"
      ],
      "authorship_tag": "ABX9TyOJrZa0/ww4hwCejwUfM7zh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duongdqq/TF_guide/blob/master/3_train_n_evaluation_w_builtin_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtr67YAvtI7x"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNzVwBbMsb9d"
      },
      "source": [
        "# API overview: a first end-to-end example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTemSzGStn9"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name='digits')\n",
        "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0q84zbNtHeQ"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muNQYNSNJcZv",
        "outputId": "a92114f8-9482-4997-a7ed-548ca68a8646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqnOGN3tJrsf",
        "outputId": "f715ece4-90ec-4e64-e7c4-1e202bfb6fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(len(x_train))\n",
        "print(len(x_val))\n",
        "print(len(x_test))\n",
        "print('-'*10)\n",
        "print(len(y_train))\n",
        "print(len(y_val))\n",
        "print(len(y_test))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n",
            "10000\n",
            "----------\n",
            "50000\n",
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB99cvfDKZJV"
      },
      "source": [
        "# specify the training configuration\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34lbGarkNEnZ",
        "outputId": "4fd901ed-bbd5-47cb-d9f6-e7af7c1b270a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# call fit() to slide data into batches\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=2,\n",
        "    validation_data=(x_val, y_val)\n",
        ") "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3370 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.1926 - val_sparse_categorical_accuracy: 0.9469\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.1581 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.1307 - val_sparse_categorical_accuracy: 0.9624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib5WhrxoNwBs",
        "outputId": "330c7283-1545-408d-83fd-bc7639681da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# history holds record of the loss values and metric values during training\n",
        "history.history"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.33696964383125305, 0.158108651638031],\n",
              " 'sparse_categorical_accuracy': [0.9051600098609924, 0.9535199999809265],\n",
              " 'val_loss': [0.19258376955986023, 0.13067319989204407],\n",
              " 'val_sparse_categorical_accuracy': [0.9469000101089478, 0.9624000191688538]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50Zi8DQPQ18",
        "outputId": "053e4541-2ac4-4190-a82c-92ae783c495c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# evaluate model on the test data\n",
        "results = model.evaluate(x_val, y_val, batch_size=128)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 1ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RZTnKUTYLGN",
        "outputId": "06fe2809-4b22-4340-8851-f2c5d505aed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "predictions = model.predict(x_test[:3])\n",
        "predictions"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.90244088e-06, 1.83373785e-07, 2.88954587e-04, 3.35387624e-04,\n",
              "        8.55224780e-09, 2.74164881e-06, 1.74435411e-10, 9.99348342e-01,\n",
              "        2.87892863e-06, 1.85877871e-05],\n",
              "       [1.04839070e-04, 2.59855355e-04, 9.98557150e-01, 1.05859537e-03,\n",
              "        4.52650167e-10, 7.09124015e-06, 3.83009865e-06, 1.70186269e-07,\n",
              "        8.47966749e-06, 1.73505406e-08],\n",
              "       [1.21268109e-04, 9.94431674e-01, 1.61981746e-03, 1.44066449e-04,\n",
              "        2.22408096e-04, 6.29434871e-05, 1.95612767e-04, 2.95745302e-03,\n",
              "        1.13250535e-04, 1.31512061e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnvUqcKDYlTH",
        "outputId": "5fb17a3c-e694-4b99-abe7-bd6d0d54badd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aeof2OUOZ_m-"
      },
      "source": [
        "# The compile() method: specifying a loss, metrics, and an optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyjkbqgQYCPX"
      },
      "source": [
        "* Specify optimizer, loss function and metrics by model.compile()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-8vBFUGYq0m"
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name='digits')\n",
        "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm90V1vdZGyP"
      },
      "source": [
        "* 1st method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgotW7R0YI44"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        ")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhihRto3Y2fI"
      },
      "source": [
        "* If model has multiple outputs, specify different losses and metrics for each output, and modulate the contribution of each output to the total loss of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz74j5jPZJc4"
      },
      "source": [
        "* 2nd method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZF3TGZZDtp"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwehJBbtZo4O"
      },
      "source": [
        "* For later reuse, put the model definition and compile step in function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd4Oz_q9Z4e5"
      },
      "source": [
        "def get_uncompiled_model():\n",
        "  inputs = keras.Input(shape=(784,), name='digits')\n",
        "  x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "  x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "  outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bnbJP9JaGSH"
      },
      "source": [
        "def get_compiled_model():\n",
        "  model = get_uncompiled_model()\n",
        "  model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        "  )\n",
        "  return model"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRwHHKBFac7f"
      },
      "source": [
        "### Many built-in optimizers, losses, and metrics are available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRY9jF8baW89"
      },
      "source": [
        "* Optimizers\n",
        "  * SDG() with or without momentum\n",
        "  * RMSprop()\n",
        "  * Adam()\n",
        "* Losses\n",
        "  * MeanSquaredError()\n",
        "  * KLDivergence()\n",
        "  * CosineSimilarity()\n",
        "* Metrics\n",
        "  * AUC()\n",
        "  * Precision()\n",
        "  * Recall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6-ZhZkEaf3O"
      },
      "source": [
        "### Custom losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owXHR-gmeZHD"
      },
      "source": [
        "* 1st method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A78qf_XjdODE"
      },
      "source": [
        "def custom_mean_squared_error(y_true, y_pred):\n",
        "  return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "model = get_uncompiled_model()\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=custom_mean_squared_error\n",
        ")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zin2b7s_d0YN",
        "outputId": "eb86d14a-727a-4736-bc1d-ba7c30451116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
        "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.0160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8acfd828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTJjuHtIea5q"
      },
      "source": [
        "* 2nd method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N2HpyOTfrVo"
      },
      "source": [
        "* __init__(self): accept parameters to pass during the call of your loss function\n",
        "* call(self, y_true, y_pred): use the targets (y_true) and the model predictions (y_pred) to compute the model's loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ERVusXTPHNk",
        "outputId": "7c608cad-b555-4eda-8758-e8cc0cf0e875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class CustomMSE(keras.losses.Loss):\n",
        "  def __init__(self, regularization_factor=0.1, name='custom_mse'):\n",
        "    super().__init__(name=name)\n",
        "    self.regularization_factor = regularization_factor\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
        "    reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
        "    return mse + reg * self.regularization_factor\n",
        "\n",
        "\n",
        "model = get_compiled_model()\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=CustomMSE())\n",
        "\n",
        "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
        "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.0387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8ab9cf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfStowMgaikf"
      },
      "source": [
        "### Custom metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2ae4pI8f1Wb"
      },
      "source": [
        "* __init__(self), in which you will create state variables for your metric.\n",
        "* update_state(self, y_true, y_pred, sample_weight=None), which uses the targets * y_true and the model predictions y_pred to update the state variables.\n",
        "* result(self), which uses the state variables to compute the final results.\n",
        "* reset_states(self), which reinitializes the state of the metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE70J4PBg3NY"
      },
      "source": [
        "* State update and results computation are kept separate (in update_state() and result(), respectively) because in some cases, results computation might be very expensive, and would only be done periodically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RgOAV4-g7js"
      },
      "source": [
        "class CategoricalTruePositives(keras.metrics.Metric):\n",
        "  def __init__(self, name='categorical_true_positives', **kwargs):\n",
        "    super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
        "    self.true_positives = self.add_weight(name='ctp', initializer='zeros')\n",
        "\n",
        "  \n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
        "    values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n",
        "    values = tf.cast(values, 'float32')\n",
        "    if sample_weight is not None:\n",
        "      sample_weight = tf.cast(sample_weight, 'float32')\n",
        "      values = tf.multiply(values, sample_weight)\n",
        "    self.true_positives.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "  \n",
        "  def result(self):\n",
        "    return self.true_positives\n",
        "\n",
        "  \n",
        "  def reset_states(self):\n",
        "  # The state of the metric will be reset at the start of each epoch.\n",
        "    self.true_positives.assign(0.0)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah4Qav2iK0Vl",
        "outputId": "3e28fc20-0590-4099-cf7e-b77d7407830a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model = get_uncompiled_model()\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[CategoricalTruePositives()])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=3)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.3975 - categorical_true_positives: 44462.0000\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1924 - categorical_true_positives: 47199.0000\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 0.1443 - categorical_true_positives: 47882.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8ab00d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2ieKPfDalq0"
      },
      "source": [
        "### Handling losses and metrics that don't fit the standard signature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmwP_eY0P-TF"
      },
      "source": [
        "* The overwhelming majority of losses and metrics can be computed from y_true and y_pred, where y_pred is an output of your model. \n",
        "* But not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output.\n",
        "\n",
        "* In such cases, you can call self.add_loss(loss_value) from inside the call method of a custom layer. \n",
        "* Losses added in this way get added to the \"main\" loss during training (the one passed to compile()). \n",
        "* Here's a simple example that adds activity regularization (note that activity regularization is built-in in all Keras layers -- this layer is just for the sake of providing a concrete example):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpEONJB8Q_p8",
        "outputId": "dc124225-5988-44bd-9802-71dcd0945ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class ActivityRegularizationLayer(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
        "    return inputs  # pass through layer\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name='digits')\n",
        "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
        "\n",
        "# insert activity regurlarization as a layer\n",
        "x = ActivityRegularizationLayer()(x)\n",
        "\n",
        "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
        "outputs = layers.Dense(10, name='predictions')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 1s 3ms/step - loss: 3.0167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8a9aefd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qvxmcEVVwpd"
      },
      "source": [
        "* You can do the same for logging metric values, using add_metric():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG3xV96tVwDL",
        "outputId": "1f5e84a0-d806-420e-fe51-ffc1e705dc5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class MetricLoggingLayer(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    self.add_metric(keras.backend.std(inputs), \n",
        "                    name='std_of_activation', \n",
        "                    aggregation='mean')\n",
        "    return inputs\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "\n",
        "# Insert std logging as a layer.\n",
        "x = MetricLoggingLayer()(x)\n",
        "\n",
        "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3457 - std_of_activation: 0.9714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8aeb80f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU-g-f8IWxvw"
      },
      "source": [
        "* In the Functional API, you can also call \n",
        "* model.add_loss(loss_tensor), or \n",
        "* model.add_metric(metric_tensor, name, aggregation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_NBIKNOXYdW",
        "outputId": "444c5424-00a2-48fd-fffd-5f74903a9f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "inputs = keras.Input(shape=(784,), name='digits')\n",
        "x1 = layers.Dense(64, 'relu', name='dense1')(inputs)\n",
        "x2 = layers.Dense(64, 'relu', name='dense2')(x1)\n",
        "outputs = layers.Dense(10, name='predictions')(x2)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
        "model.add_metric(keras.backend.std(x1), name='std_of_activation', aggregation='mean')\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "model.fit(x_train, y_train, batch_size=256, epochs=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196/196 [==============================] - 1s 3ms/step - loss: 5.1813 - std_of_activation: 0.0067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8ac06ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5lgNUO_a35-"
      },
      "source": [
        "* Note that when you pass losses via add_loss(), it becomes possible to call compile() without a loss function, since the model already has a loss to minimize.\n",
        "* Consider the following LogisticEndpoint layer: it takes as inputs targets & logits, and it tracks a crossentropy loss via add_loss(). It also tracks classification accuracy via add_metric()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Y6Dzbua_Px"
      },
      "source": [
        "class LogisticEndpoint(keras.layers.Layer):\n",
        "  def __init__(self, name=None):\n",
        "    super(LogisticEndpoint, self).__init__(name=name)\n",
        "    self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
        "\n",
        "  def call(self, targets, logits, sample_weights=None):\n",
        "    # Compute the training-time loss value and add it\n",
        "    # to the layer using `self.add_loss()`.\n",
        "    loss = self.loss_fn(targets, logits, sample_weights)\n",
        "    self.add_loss(loss)\n",
        "\n",
        "    # Log accuracy as a metric and add it\n",
        "    # to the layer using `self.add_metric()`.\n",
        "    acc = self.accuracy_fn(targets, logits, sample_weights)\n",
        "    self.add_metric(acc, name='accuracy')\n",
        "\n",
        "    # Return the inference-time prediction tensor (for `.predict()`).\n",
        "    return tf.nn.softmax(logits)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq87ct6maM6N"
      },
      "source": [
        "* You can use it in a model with two inputs (input data & targets), compiled without a loss argument, like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyOYILe-aO-D",
        "outputId": "e3e963d6-4cb4-48fe-c2d0-0d2e64a44ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "inputs = keras.Input(shape=(3,), name='inputs')\n",
        "targets = keras.Input(shape=(10, ), name='targets')\n",
        "logits = keras.layers.Dense(10)(inputs)\n",
        "predictions = LogisticEndpoint(name='pred')(logits, targets)\n",
        "\n",
        "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
        "model.compile(optimizer='adam')  \n",
        "\n",
        "data = {'inputs': np.random.random((3,3)),\n",
        "        'targets': np.random.random((3,10))}\n",
        "\n",
        "model.fit(data)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0022 - binary_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcdac799dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52r554lBascH"
      },
      "source": [
        "### Automatically setting apart a validation holdout set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW9LVNndd2zy"
      },
      "source": [
        "* Here's another option: the argument validation_split allows you to automatically reserve part of your training data for validation. The argument value represents the fraction of the data to be reserved for validation, so it should be set to a number higher than 0 and lower than 1. For instance, validation_split=0.2 means \"use 20% of the data for validation\", and validation_split=0.6 means \"use 60% of the data for validation\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KGqiepgeSUb",
        "outputId": "301b18dc-11ba-4809-b18b-123e383fd1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3646 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.2285 - val_sparse_categorical_accuracy: 0.9323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd86864668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQO0LHUvevNA"
      },
      "source": [
        "# Training & evaluation from tf.data Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feg2rfVGODNr"
      },
      "source": [
        "* the case where your data comes in the form of a tf.data.Dataset object\n",
        "* tf.data API is a set of utilities in TF 2.0 for loading and preprocessing data in a way that is fast and scalable\n",
        "* can pass a Dataset instance directly to the methods fit(), evaluate(), and predict()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN4BUPlrOmQ1",
        "outputId": "e0aff1ae-e5aa-4009-9849-839f560e9f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(64)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=3)\n",
        "\n",
        "result = model.evaluate(test_dataset)\n",
        "dict(zip(model.metrics_names, results))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3306 - sparse_categorical_accuracy: 0.9059\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9531\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.1163 - sparse_categorical_accuracy: 0.9648\n",
            "157/157 [==============================] - 0s 1ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.13067319989204407,\n",
              " 'sparse_categorical_accuracy': 0.9624000191688538}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SumAHiTWAa8Q"
      },
      "source": [
        "* the Dataset is reset at the end of each epoch, so it can be reused of the next epoch.\n",
        "* If you want to run training only on a specific number of batches from this Dataset, you can pass the steps_per_epoch argument, which specifies how many training steps the model should run using this Dataset before moving on to the next epoch.\n",
        "* If you do this, the dataset is not reset at the end of each epoch, instead we just keep drawing the next batches. The dataset will eventually run out of data (unless it is an infinitely-looping dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aONYT5raqzY-",
        "outputId": "a7215687-23ea-460c-e969-64cceb947fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs = 3, steps_per_epoch=100)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.7838 - sparse_categorical_accuracy: 0.8039\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3771 - sparse_categorical_accuracy: 0.8967\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3238 - sparse_categorical_accuracy: 0.9039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd855dc390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIJkk_7efD-E"
      },
      "source": [
        "## Using a validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAnr3hb-teqo"
      },
      "source": [
        "* pass a Dataset instance as the validation_data argument in fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_GIArgctnDG",
        "outputId": "32a47cfa-bc34-4238-ae87-31278242644e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(64)\n",
        "\n",
        "model.fit(train_dataset, validation_data=val_dataset, epochs=1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 3ms/step - loss: 0.3376 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.1771 - val_sparse_categorical_accuracy: 0.9481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd855dc198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21CYO2pcucys"
      },
      "source": [
        "* At the end of each epoch, the model will iterate over the validation dataset and compute the validation loss and validation metrics.\n",
        "* If you want to run validation only on a specific number of batches from this dataset, you can pass the validation_steps argument, which specifies how many validation steps the model should run with the validation dataset before interrupting validation and moving on to the next epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_pzc4UpvoB0",
        "outputId": "b418234b-afc7-4bf2-a6d9-874f8ec6e0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(64)\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    epochs=1,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=10\n",
        ")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3449 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.3138 - val_sparse_categorical_accuracy: 0.9234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd854d8438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pecoP7dXznjV"
      },
      "source": [
        "* the validation dataset will be reset after each use (so that you will always be evaluating on the same samples from epoch to epoch).\n",
        "* The argument validation_split (generating a holdout set from the training data) is not supported when training from Dataset objects, since this feature requires the ability to index the samples of the datasets, which is not possible in general with the Dataset API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t64hkIFKfdEG"
      },
      "source": [
        "# Other input formats supported"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKHHu0T20HdP"
      },
      "source": [
        "* Pandas dataframes\n",
        "* from python generator that yield batches of data & labels\n",
        "* In particular, the keras.utils.Sequence class offers a simple interface to build Python data generators that are multiprocessing-aware and can be shuffled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fxDiOsu0YX8"
      },
      "source": [
        "* In general, we recommend that you use:\n",
        "\n",
        "* NumPy input data if your data is small and fits in memory\n",
        "* Dataset objects if you have large datasets and you need to do distributed training\n",
        "* Sequence objects if you have large datasets and you need to do a lot of custom Python-side processing that cannot be done in TensorFlow (e.g. if you rely on external libraries for data loading or preprocessing).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWFt5mejfiK-"
      },
      "source": [
        "# Using a keras.utils.Sequence object as input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUYm-IqI0lNL"
      },
      "source": [
        "* keras.utils.Sequence is a utility that you can subclass to obtain a Python generator with two important properties:\n",
        "\n",
        "* It works well with multiprocessing.\n",
        "* It can be shuffled (e.g. when passing shuffle=True in fit())."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80t_zCo30sm6"
      },
      "source": [
        "* A Sequence must implement two methods:\n",
        "\n",
        "* __getitem__\n",
        "* __len__\n",
        "* The method __getitem__ should return a complete batch. If you want to modify your dataset between epochs, you may implement on_epoch_end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3GmMFCv0xAJ",
        "outputId": "39e54522-c643-41c4-81e5-fff06d960955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from keras.utils import Sequence\n",
        "\n",
        "class CIFAR10Sequence(Sequence):\n",
        "  def __init__(self, filenames, labels, batch_size):\n",
        "    self.filenames, self.labels = filenames, labels\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
        "\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "    batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "    return \n",
        "    np.array([resize(imread(filename), (200, 200)) for filename in batch_x]),\n",
        "    np.array(batch_y)\n",
        "\n",
        "\n",
        "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
        "model.fit(sequence, epochs=10)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-b52c16912a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10Sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filenames' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYP_uwHzfi_4"
      },
      "source": [
        "# Using sample weighting and class weighting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sATWxi6GBUsg"
      },
      "source": [
        "* With the default settings the weight of a sample is decided by its frequency in the dataset. \n",
        "* There are two methods to weight the data, independent of sample frequency:\n",
        "  * class weight\n",
        "  * sample weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeBvXfmCfi0M"
      },
      "source": [
        "## Class weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vTG_qxjCLoZ"
      },
      "source": [
        "* This is set by passing a dictionary to the class_weight argument to Model.fit()\n",
        "* This dictionary maps class indices to the weight that should be used for samples belonging to this class.\n",
        "* This can be used to balance classes without resampling, or to train a model that gives more importance to a particular class.\n",
        "* For instance, if class \"0\" is half as represented as class \"1\" in your data, you could use Model.fit(..., class_weight={0: 1., 1: 0.5}).\n",
        "* Here's a NumPy example where we use class weights or sample weights to give more importance to the correct classification of class #5 (which is the digit \"5\" in the MNIST dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2x3mImmkT6A",
        "outputId": "b421a3b5-3174-4f8e-bf8c-ac0e8f4116ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class_weight = {\n",
        "    0: 1.0,\n",
        "    1: 1.0,\n",
        "    2: 1.0,\n",
        "    3: 1.0,\n",
        "    4: 1.0,\n",
        "    5: 2.0,  # noticeable\n",
        "    6: 1.0,\n",
        "    7: 1.0,\n",
        "    8: 1.0,\n",
        "    9: 1.0\n",
        "}\n",
        "\n",
        "print('fit with class weight')\n",
        "model = get_compiled_model()\n",
        "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fit with class weight\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3787 - sparse_categorical_accuracy: 0.8991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd84a82710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1smZRcvnfvSb"
      },
      "source": [
        "## Sample weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryKaExd_luZT"
      },
      "source": [
        "* A \"sample weights\" array is an array of numbers that specify how much weight each sample in a batch should have in computing the total loss. \n",
        "* It is commonly used in imbalanced classification problems (the idea being to give more weight to rarely-seen classes).\n",
        "* When the weights used are ones and zeros, the array can be used as a mask for the loss function (entirely discarding the contribution of certain samples to the total loss).\n",
        "* For fine grained control, or if you are not building a classifier, you can use \"sample weights\".\n",
        "  * When training from NumPy data: Pass the sample_weight argument to Model.fit().\n",
        "  * When training from tf.data or any other sort of iterator: Yield (input_batch, label_batch, sample_weight_batch) tuples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LcxwGNomzaP",
        "outputId": "892613d6-f760-407e-e744-637ba9a8d819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sample_weight = np.ones(shape=(len(y_train),))\n",
        "sample_weight[y_train == 5] = 2.0\n",
        "\n",
        "print('fit with sample weight')\n",
        "model = get_compiled_model()\n",
        "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fit with sample weight\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3588 - sparse_categorical_accuracy: 0.9060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd84935f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BwBVmmaqJLI",
        "outputId": "47e99d3d-b4ae-4bf7-d019-ebc6da0821fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_weight = np.ones(shape=(len(y_train),))\n",
        "sample_weight[y_train == 5] = 2.0\n",
        "\n",
        "# create a dataset that includes sample weights\n",
        "# 3rd element in the return tuple\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "model = get_compiled_model()\n",
        "model.fit(train_dataset, epochs=1)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3751 - sparse_categorical_accuracy: 0.9025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd847c8390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYN6zW2mf78u"
      },
      "source": [
        "# Passing data to multi-input, multi-output models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPOpOzfstbZv"
      },
      "source": [
        "* Consider the following model, which has an image input of shape (32, 32, 3) (that's (height, width, channels)) and a timeseries input of shape (None, 10) (that's (timesteps, features))\n",
        "* Our model will have two outputs computed from the combination of these inputs: a \"score\" (of shape (1,)) and a probability distribution over five classes (of shape (5,))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVI6GBvdtyYY"
      },
      "source": [
        "image_input = keras.Input(shape=(32, 32, 3), name='img_input')\n",
        "timeseries_input = keras.Input(shape=(None, 10), name='ts_input')\n",
        "\n",
        "x1 = layers.Conv2D(3, 3)(image_input)\n",
        "x1 = layers.GlobalMaxPooling2D()(x1)\n",
        "\n",
        "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
        "x2 = layers.GlobalMaxPooling1D()(x2)\n",
        "\n",
        "x = layers.concatenate([x1, x2])\n",
        "\n",
        "score_output = layers.Dense(1, name='score_output')(x)\n",
        "class_output = layers.Dense(5, name='class_output')(x)\n",
        "\n",
        "model = keras.Model(\n",
        "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
        ")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdZPHc3eyenv",
        "outputId": "c075958d-d60c-4302-f2bb-e068f23c395b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "keras.utils.plot_model(model, '123.png', show_shapes=True)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQGX4rMlzF1f"
      },
      "source": [
        "* At compilation time, we can specify different losses to different outputs, by passing the loss functions as a list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w_oOZpvzFa9"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()]\n",
        ")"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb4Lm4Abzqvg"
      },
      "source": [
        "* likewise for metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLZ0BrKyzCSF"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
        "    metrics=[\n",
        "             [\n",
        "              keras.metrics.MeanAbsolutePercentageError(),\n",
        "              keras.metrics.MeanAbsoluteError()\n",
        "             ],\n",
        "             [keras.metrics.CategoricalAccuracy()]\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fwjM1ff0eBx"
      },
      "source": [
        "* Since we gave names to our output layers, we could also specify per-output losses and metrics via a dict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mNHjOkK0fpB"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={\n",
        "        'score_output': keras.losses.MeanSquaredError(), \n",
        "        'class_output': keras.losses.CategoricalCrossentropy()\n",
        "        },\n",
        "    metrics={\n",
        "             'score_output': [\n",
        "              keras.metrics.MeanAbsolutePercentageError(),\n",
        "              keras.metrics.MeanAbsoluteError()\n",
        "             ],\n",
        "             'class_output': [keras.metrics.CategoricalAccuracy()]\n",
        "    }\n",
        ")"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGJk1Wjj1ofe"
      },
      "source": [
        "* It's possible to give different weights to different output-specific losses (for instance, one might wish to privilege the \"score\" loss in our example, by giving to 2x the importance of the class loss), using the loss_weights argument:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9HHKZB-2W3F"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={\n",
        "        'score_output': keras.losses.MeanSquaredError(), \n",
        "        'class_output': keras.losses.CategoricalCrossentropy()\n",
        "        },\n",
        "    metrics={\n",
        "             'score_output': [\n",
        "              keras.metrics.MeanAbsolutePercentageError(),\n",
        "              keras.metrics.MeanAbsoluteError()\n",
        "             ],\n",
        "             'class_output': [keras.metrics.CategoricalAccuracy()]\n",
        "    },\n",
        "    loss_weights={\n",
        "        'score_output': 2.0,\n",
        "        'class_output': 1.0}\n",
        ")"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4-iBalP3OBe"
      },
      "source": [
        "* You could also chose not to compute a loss for certain outputs, if these outputs meant for prediction but not for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTW4yHbX3m2U"
      },
      "source": [
        "# list loss version\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[\n",
        "          None,\n",
        "          keras.losses.CategoricalCrossentropy()\n",
        "    ]\n",
        ")\n",
        "\n",
        "# or dict loss version\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss={\n",
        "          'class_output': keras.losses.CategoricalCrossentropy()\n",
        "    }\n",
        ")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQlkS7B6G7E"
      },
      "source": [
        "* Passing data to a multi-input or multi-output model in fit works in a similar way as specifying a loss function in compile: \n",
        "* you can pass lists of NumPy arrays (with 1:1 mapping to the outputs that received a loss function) or dicts mapping output names to NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZIUBeEj6Sy6",
        "outputId": "75a35847-d673-40a5-f2b5-4003b8859223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
        "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
        ")\n",
        "\n",
        "# Generate dummy NumPy data\n",
        "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
        "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
        "score_targets = np.random.random_sample(size=(100, 1))\n",
        "class_targets = np.random.random_sample(size=(100, 5))\n",
        "\n",
        "# Fit on lists\n",
        "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
        "\n",
        "# Alternatively, fit on dicts\n",
        "model.fit(\n",
        "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
        "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
        "    batch_size=32,\n",
        "    epochs=1,\n",
        ")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 7ms/step - loss: 22.8800 - score_output_loss: 3.9990 - class_output_loss: 18.8810\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 21.3581 - score_output_loss: 2.9036 - class_output_loss: 18.4545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd804fce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhrUfTnQ6lhN"
      },
      "source": [
        "* Here's the Dataset use case: similarly as what we did for NumPy arrays, the Dataset should return a tuple of dicts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wGBIIuu6mc_",
        "outputId": "4274d89e-786d-4337-ac47-905a1e239435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (\n",
        "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
        "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
        "    )\n",
        "    \n",
        ")\n",
        "\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "model.fit(train_dataset, epochs=1)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 12ms/step - loss: 21.4071 - score_output_loss: 2.5001 - class_output_loss: 18.9070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd8065d080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edJbU33df-2d"
      },
      "source": [
        "# Using callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyaFAtGZ1Lno"
      },
      "source": [
        "* Callbacks in Keras are objects that are called at different points during training (at the start of an epoch, at the end of a batch, at the end of an epoch, etc.)\n",
        "* and which can be used to implement behaviors such as:\n",
        "  * Doing validation at different points during training (beyond the built-in per-epoch validation)\n",
        "  * Checkpointing the model at regular intervals or when it exceeds a certain accuracy threshold\n",
        "  * Changing the learning rate of the model when training seems to be plateauing\n",
        "  * Doing fine-tuning of the top layers when training seems to be plateauing\n",
        "  * Sending email or instant message notifications when training ends or where a certain performance threshold is exceeded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAqpzNPk4gHX",
        "outputId": "892fb42e-de7d-436e-d5a5-106a102d6740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "callbacks = [\n",
        "             keras.callbacks.EarlyStopping(\n",
        "                 monitor = 'val_loss',  # stop training when val_loss is no longer improving\n",
        "                 min_delta=1e-2,  # no longer improving being defined as no better than 1e-2 less\n",
        "                 patience=2,  # no longer improving being futher defined as for at least 2 epochs\n",
        "                 verbose=1\n",
        "             )\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.3744 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.2387 - val_sparse_categorical_accuracy: 0.9281\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1747 - sparse_categorical_accuracy: 0.9488 - val_loss: 0.2035 - val_sparse_categorical_accuracy: 0.9362\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9540\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.1030 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1514 - val_sparse_categorical_accuracy: 0.9533\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9737 - val_loss: 0.1378 - val_sparse_categorical_accuracy: 0.9589\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.1369 - val_sparse_categorical_accuracy: 0.9627\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 1s 2ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1406 - val_sparse_categorical_accuracy: 0.9636\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd84907080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXmRw-rjgKiH"
      },
      "source": [
        "## Many built-in callbacks are available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cwVkQMa8L6i"
      },
      "source": [
        "* ModelCheckingpoint: save the model\n",
        "* EearlyStopping: stop training when training is no longer improving the validation metrics\n",
        "* TensorBoard: periodically write model logs that can be visualized in TensorBoard \n",
        "* CSVLogger: streams loss and metrics data to a CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXazss5xgNwR"
      },
      "source": [
        "## Writing your own callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlEvCohC9k3x"
      },
      "source": [
        "* You can create a custom callback by extending the base class keras.callbacks.Callback. \n",
        "* A callback has access to its associated model through the class property self.model.\n",
        "* Here's a simple example saving a list of per-batch loss values during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiM6SrQ_-RQW"
      },
      "source": [
        "class LossHistory(keras.callbacks.Callback):\n",
        "  def on_train_begin(self, logs):\n",
        "    self.per_batch_losses = []\n",
        "\n",
        "  def on_train_end(self, logs):\n",
        "    self.per_batch_losses.append(logs.get('loss'))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7RpQLo9gVzI"
      },
      "source": [
        "# Checkpointing models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rylSVT6U_S54"
      },
      "source": [
        "* When you're training model on relatively large datasets, it's crucial to save checkpoints of your model at frequent intervals.\n",
        "* The easiest way to achieve this is with the ModelCheckpoint callback:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt8stPJW_Y_y",
        "outputId": "4cc3cf0c-1aa3-46f6-ff00-34bf2a446551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "model = get_compiled_model()\n",
        "\n",
        "callbacks = [\n",
        "             keras.callbacks.ModelCheckpoint(\n",
        "             # Path where to save the model\n",
        "             # The two parameters below mean that we will overwrite\n",
        "             # the current checkpoint if and only if\n",
        "             # the `val_loss` score has improved.\n",
        "             # The saved model name will include the current epoch.\n",
        "             filepath='mymodel_{epoch}',\n",
        "             monitor='val_loss',\n",
        "             verbose=1,\n",
        "             save_best_only=True\n",
        "             )\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=2,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "599/625 [===========================>..] - ETA: 0s - loss: 0.3798 - sparse_categorical_accuracy: 0.8913\n",
            "Epoch 00001: val_loss improved from inf to 0.24003, saving model to mymodel_1\n",
            "INFO:tensorflow:Assets written to: mymodel_1/assets\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.3744 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.2400 - val_sparse_categorical_accuracy: 0.9278\n",
            "Epoch 2/2\n",
            "610/625 [============================>.] - ETA: 0s - loss: 0.1763 - sparse_categorical_accuracy: 0.9488\n",
            "Epoch 00002: val_loss improved from 0.24003 to 0.18742, saving model to mymodel_2\n",
            "INFO:tensorflow:Assets written to: mymodel_2/assets\n",
            "625/625 [==============================] - 2s 3ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.1874 - val_sparse_categorical_accuracy: 0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd856a0c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXSnEP0B1pc"
      },
      "source": [
        "* The ModelCheckpoint callback can be used to implement fault-tolerance: the ability to restart training from the last saved state of the model in case training gets randomly interrupted. Here's a basic example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9IWsEjyB3Fo",
        "outputId": "0030c37b-250c-427a-8575-773c69b0cc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# prepare a directory to store all the checkpoint\n",
        "checkpoint_dir = './ckpt'\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.makedirs(checkpoint_dir)\n",
        "\n",
        "\n",
        "def make_or_restore_model():\n",
        "  # either restore the lastest model or create a fresh one\n",
        "  # if there is no ckpt available\n",
        "  ckpt = [checkpoint_dir + '/' + name for name in os.listdir(checkpoint_dir)]\n",
        "  if ckpt:\n",
        "    lastest_ckpt = max(clpt, key=os.path.getctime)\n",
        "    print('restoring from', lastest_ckpt)\n",
        "    return keras.models.load_model(lastest_ckpt)\n",
        "  print('create a new model')\n",
        "  return get_compiled_model()\n",
        "\n",
        "\n",
        "model = make_or_restore_model()\n",
        "callbacks = [\n",
        "             # this callback saves a SavedModel every 100 batches\n",
        "             # we include the training loss in the saved model name\n",
        "             keras.callbacks.ModelCheckpoint(\n",
        "                 filepath = checkpoint_dir + '/ckpt-loss={loss:.2f}',\n",
        "                 save_freq=100\n",
        "             )\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train, \n",
        "    epochs=1,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create a new model\n",
            "  71/1563 [>.............................] - ETA: 2s - loss: 1.1430 - sparse_categorical_accuracy: 0.6919INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.98/assets\n",
            " 176/1563 [==>...........................] - ETA: 5s - loss: 0.7533 - sparse_categorical_accuracy: 0.7912INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.71/assets\n",
            " 299/1563 [====>.........................] - ETA: 5s - loss: 0.5929 - sparse_categorical_accuracy: 0.8346INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.59/assets\n",
            " 371/1563 [======>.......................] - ETA: 6s - loss: 0.5433 - sparse_categorical_accuracy: 0.8495INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.53/assets\n",
            " 467/1563 [=======>......................] - ETA: 6s - loss: 0.4952 - sparse_categorical_accuracy: 0.8615INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.48/assets\n",
            " 575/1563 [==========>...................] - ETA: 5s - loss: 0.4596 - sparse_categorical_accuracy: 0.8701INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.45/assets\n",
            " 690/1563 [============>.................] - ETA: 4s - loss: 0.4246 - sparse_categorical_accuracy: 0.8798INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.42/assets\n",
            " 770/1563 [=============>................] - ETA: 4s - loss: 0.4058 - sparse_categorical_accuracy: 0.8847INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.40/assets\n",
            " 868/1563 [===============>..............] - ETA: 4s - loss: 0.3851 - sparse_categorical_accuracy: 0.8899INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.38/assets\n",
            " 971/1563 [=================>............] - ETA: 3s - loss: 0.3687 - sparse_categorical_accuracy: 0.8941INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.36/assets\n",
            "1069/1563 [===================>..........] - ETA: 2s - loss: 0.3555 - sparse_categorical_accuracy: 0.8979INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.35/assets\n",
            "1167/1563 [=====================>........] - ETA: 2s - loss: 0.3432 - sparse_categorical_accuracy: 0.9011INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.34/assets\n",
            "1284/1563 [=======================>......] - ETA: 1s - loss: 0.3309 - sparse_categorical_accuracy: 0.9046INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.33/assets\n",
            "1399/1563 [=========================>....] - ETA: 1s - loss: 0.3191 - sparse_categorical_accuracy: 0.9078INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.32/assets\n",
            "1466/1563 [===========================>..] - ETA: 0s - loss: 0.3130 - sparse_categorical_accuracy: 0.9096INFO:tensorflow:Assets written to: ./ckpt/ckpt-loss=0.31/assets\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3044 - sparse_categorical_accuracy: 0.9121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd7d94e630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoCow1m6gaF_"
      },
      "source": [
        "# Using learning rate schedules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Q-gpexWrWT"
      },
      "source": [
        "* A common pattern when training deep learning models is to gradually reduce the learning as training progresses. This is generally known as \"learning rate decay\".\n",
        "* The learning decay schedule could be static (fixed in advance, as a function of the current epoch or the current batch index), or dynamic (responding to the current behavior of the model, in particular the validation loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuw32injgemQ"
      },
      "source": [
        "## Passing a schedule to an optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NirCeI70Xf4X"
      },
      "source": [
        "* You can easily use a static learning rate decay schedule by passing a schedule object as the learning_rate argument in your optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmIQGjn5XimT"
      },
      "source": [
        "initial_lr = 0.1\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_lr, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ")\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr5wtvpvYRCD"
      },
      "source": [
        "* Several built-in schedules are available: \n",
        "  * ExponentialDecay, \n",
        "  * PiecewiseConstantDecay, \n",
        "  * PolynomialDecay, and \n",
        "  * InverseTimeDecay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcBVS_fhgfxJ"
      },
      "source": [
        "## Using callbacks to implement a dynamic learning rate schedule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWoTpnAZpTa"
      },
      "source": [
        "* A dynamic learning rate schedule (for instance, decreasing the learning rate when the validation loss is no longer improving) cannot be achieved with these schedule objects since the optimizer does not have access to validation metrics.\n",
        "* However, callbacks do have access to all metrics, including validation metrics! \n",
        "* You can thus achieve this pattern by using a callback that modifies the current learning rate on the optimizer. \n",
        "* In fact, this is even built-in as the ReduceLROnPlateau callback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUZlHV_jgkZR"
      },
      "source": [
        "# Visualizing loss and metrics during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qHu6jeEcoKz"
      },
      "source": [
        "* The best way to keep an eye on your model during training is to use TensorBoard, a browser-based application that you can run locally that provides you with:\n",
        "  * Live plots of the loss and metrics for training and evaluation\n",
        "  * (optionally) Visualizations of the histograms of your layer activations\n",
        "  * (optionally) 3D visualizations of the embedding spaces learned by your Embedding layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I93kC-scglPo"
      },
      "source": [
        "## Using the TensorBoard callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDiEVRkkfHHL"
      },
      "source": [
        "* The easiest way to use TensorBoard with a Keras model and the fit method is the TensorBoard callback.\n",
        "* In the simplest case, just specify where you want the callback to write logs, and you're good to go:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSoTL8dogOS3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}